{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71045ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import anthropic\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be875798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Now you can access variables using os.getenv()\n",
    "api_key = os.getenv(\"CLAUDE_API_KEY\")\n",
    "  # For debugging purposes, remove in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8540bade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Anthropic client\n",
    "client = anthropic.Anthropic(api_key=api_key)\n",
    "\n",
    "# Folder containing batch files\n",
    "BATCH_FOLDER = \"batch_files\"\n",
    "BATCH_LOG_FILE = \"batch_responses_log.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d81b5a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available batch files:\n",
      "1. choice_prompts_with_norm.jsonl\n",
      "2. choice_prompts_without_norm.jsonl\n",
      "3. immoral_act_with_norm_prompts.jsonl\n",
      "4. immoral_act_without_norm_prompts.jsonl\n",
      "5. with_moralAction_immoralConsequnece_base_prompts.jsonl\n",
      "6. with_immoralAction_moralConsequnece_base_prompts.jsonl\n",
      "7. injection_moralAction_immoralOutcome_prompts.jsonl\n",
      "8. anti_action_immoralAction_prompts.jsonl\n",
      "9. pro_outcome_immoralAction_prompts.jsonl\n",
      "10. outcome_weighted_moralAction_prompts.jsonl\n"
     ]
    }
   ],
   "source": [
    "batch_files = [f for f in os.listdir(BATCH_FOLDER) if f.endswith(\".jsonl\")]\n",
    "\n",
    "# Prompt user to select one file\n",
    "print(\"Available batch files:\")\n",
    "for i, file in enumerate(batch_files):\n",
    "    print(f\"{i + 1}. {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "123285f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch_file(filepath):\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"‚ùå File not found: {filepath}\")\n",
    "        return\n",
    "\n",
    "    filename = os.path.basename(filepath)\n",
    "    requests_to_send = []\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                try:\n",
    "                    req = json.loads(line)\n",
    "                    if \"custom_id\" in req and \"params\" in req:\n",
    "                        requests_to_send.append(req)\n",
    "                    else:\n",
    "                        print(f\"‚ö†Ô∏è Skipping malformed entry in {filename}: {line.strip()}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error parsing line in {filename}: {e}\")\n",
    "\n",
    "    print(f\"‚úÖ Loaded {len(requests_to_send)} requests from {filename}\")\n",
    "\n",
    "    if not requests_to_send:\n",
    "        print(\"‚ö†Ô∏è No valid requests found to send.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        message_batch = client.messages.batches.create(requests=requests_to_send)\n",
    "        print(\"üéØ Batch Created:\")\n",
    "        print(message_batch)\n",
    "\n",
    "        # Append the batch response to a log file\n",
    "        with open(BATCH_LOG_FILE, \"a\", encoding=\"utf-8\") as log_file:\n",
    "            log_file.write(json.dumps({\n",
    "                \"batch_file\": filename,\n",
    "                \"response\": message_batch.model_dump()\n",
    "            }, default=str) + \"\\n\")\n",
    "            print(f\"üì¶ Batch response logged in: {BATCH_LOG_FILE}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error sending batch: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8d6c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå File not found: batch_files/with_moralAction_moralConsequnece_base_prompts.jsonl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_file_path = \"batch_files/with_moralAction_immoralConsequnece_base_prompts.jsonl\"  # replace with your file\n",
    "process_batch_file(batch_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "514b6cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Manually logged batch: msgbatch_01NjacNb4xK6STxoTuAXkgzE\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Manually entered batch metadata (based on your printout)\n",
    "batch_info = {\n",
    "    \"batch_file\": \"anti_action_immoralAction_prompts.jsonl\",\n",
    "    \"response\": {\n",
    "        \"id\": \"msgbatch_01NjacNb4xK6STxoTuAXkgzE\",\n",
    "        \"archived_at\": None,\n",
    "        \"cancel_initiated_at\": None,\n",
    "        \"created_at\": datetime(2025, 5, 16, 17, 14, 56, 797993, tzinfo=timezone.utc).isoformat(),\n",
    "        \"ended_at\": None,\n",
    "        \"expires_at\": datetime(2025, 5, 17, 17, 14, 56, 797993, tzinfo=timezone.utc).isoformat(),\n",
    "        \"processing_status\": \"in_progress\",\n",
    "        \"request_counts\": {\n",
    "            \"canceled\": 0,\n",
    "            \"errored\": 0,\n",
    "            \"expired\": 0,\n",
    "            \"processing\": 12000,\n",
    "            \"succeeded\": 0\n",
    "        },\n",
    "        \"results_url\": None,\n",
    "        \"type\": \"message_batch\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Path to your log file\n",
    "BATCH_LOG_FILE = \"batch_responses_log.jsonl\"\n",
    "\n",
    "# Append the manually structured entry\n",
    "with open(BATCH_LOG_FILE, \"a\", encoding=\"utf-8\") as log_file:\n",
    "    log_file.write(json.dumps(batch_info) + \"\\n\")\n",
    "\n",
    "print(f\"üì¶ Manually logged batch: {batch_info['response']['id']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ethics-kernal",
   "language": "python",
   "name": "ethics-kernal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
